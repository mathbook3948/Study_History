oococo뉴럴네트워크(신경망)에 넣을 수 있는 자료는 오직 숫자

이미지 -> 픽셀 모음
픽셀 -> rgb
픽셀(흑백) -> (0~255) 0이 검정색, 255가 하얀색

```python
tf.keras.datasets.fashion_mnist.load_data() #keras의 데이터 가져오기
#튜플 형태 ((trainx, trainy), (testx,testy))
```
activation 
relu : 음수를 0으로 만드는 활성화 함수
softmax(카테고리 분류에 많이 사용. 마지막 노드는 카테고리의 갯수만큼-가능성 높은 카테고리가 높게 나옴. 예측된 결과를 합치면 1이 나옴), sigmoid(맞다 아니다 문제에 적합, 마지막 노드는 1개) : 0에서 1로 짜부

loss function
주로 카테고리 분류
- sparse_categorical_crossentropy => trainy가 0,1,2,...등 정수일 때
- categorical_crossentropy => trainy가 원핫인코딩 되어 있을 떄
![[Pasted image 20241107155052.png]]

```python
tf.keras.layers.Flatten() 
```
2차원 이상의 데이터를 1차원으로 짜부시켜 펴줌(가로로 나열)== 우리는 1차원 데이터를 원하지 2,3,4 차원데이터를 원하는게 아님

이미지를 flatten 하는것의 문제점
원본 이미지를 불리, 변형해서 하기 때문에 예측 모델의 응용력이 떨어진다(규칙 찾기 힘듦)
같은 사진을 조금만 이동시키거나 변형 시켜도 예측 못함


Convolutional layer
이미지를 이미지 자체로 분석하는 방법
이미지에서 중요한 정보를 추려서 복사본 20장을 만든다.(feature extraction)
각각의 이미지에는 사진의 각각 다른 특성이 담겨 있다.

convolutional layer(feature Map)이란?
원본이미지를 특징을 뽑아서 압축시키는 방법

일반 이미지 데이터에서 kernal을 통해서 만듦
kernal이란?
원하는 특징을 뽑아낼 수 있는 행렬. 행렬 계산을 통해 원하는 특징을 뽑아냄
어려운거 다 빼고 필터라고 생각하면  됨
![[Pasted image 20241107162907.png]]
tensorflow는 여러가지 커널들을 자동적용해서 레이어를 만들어준다.

알맞은 kernal을 사용하면 특성을 쉽게 파악할 수 있게 된다. 

문제점
특징의 위치가 움직이면 이동해도 어차피 데이터를 펴서 분석하기 때문에 의미가 없음

Pooling layer(Down Sampling)
Max Pooling : 최댓값만 추려서 데이터를 남김
Average Pooling : 평균값을 내서 데이터를 남김
장점
- translation invariance : 특징을 추출하고, 특징을 가운데로 모아준다.

Convolutional Neural Network 구성법
이미지->필터(kernal)->Pooling(핵심데이터가 중앙으로 모임)

```python
tf.keras.layers.Conv2D(32(생성할 장수), (3,3)(kernal의 가로세로 사이즈), padding=) #레이어 생성법
```
padding : Convolutional 레이어를 적용하면 사진의 크기가 작아질 수 밖에 없는데, 패딩을추가해서 크기를 유지해줌-속성을 same으로 

활성화 함수
relu-이미지에 많이씀
-이미지는 0~255로 구성되는데 relu는 음수를 0으로 처리해줌

ndim = 차원 
convolutional layer은 3차원이 필요함 하지만 현재 3차원 데이터
.reshape() : 모양 변경
처음부터 값을 0~1 사이로 바꾸면 더 빠르고 정확할 수 있음

```python
tf.keras.layers.MaxPooling2D((2,2)-Polling size) 4x4를 2x2로
```

보통 pooling - flatten 진행

```python
model.evaluate(testx, testy)
```
테스트에서는 훈련에 넣었던 데이터x

overfitting 문제
ai가 답을 외워버리는 현상. 새로운 문제를 제시하면 힘들어한다

```python
model.fit(trainx, trainy, validation_data=(testx,testy),epochs=5)
```
validation_data를 통해 epochs가 한번 돌때마다 채점 가능

binary_crossentropy에는 sigmoid 필요
```python
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/dataset/",
    image_size=(64,64),
    batch_size=64,
    subset="training",
    validation_split=0.2,
    seed=1234
)
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/dataset/",
    image_size=(64,64),
    batch_size=64,
    subset="validation",
    validation_split=0.2,
    seed=1234
)


tf.keras.layers.Dropout(0.2) #상위 노드 중 20%를 제거. overfitting 예방
```

```python
import tensorflow as tf

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/dataset/",
    image_size=(64,64),
    batch_size=64,
    subset="training",
    validation_split=0.2,
    seed=1234
)
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/dataset/",
    image_size=(64,64),
    batch_size=64,
    subset="validation",
    validation_split=0.2,
    seed=1234
)

model = tf.keras.Sequential([
    # tf.keras.layers.Dense(128, input_shape=(28,28),activation="relu"),
    tf.keras.layers.Conv2D(32, (3,3), padding="same", activation="relu",input_shape=(64,64,3)),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Conv2D(32, (3,3), padding="same", activation="relu"),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(32, (3,3), padding="same", activation="relu"),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation="relu"),
    tf.keras.layers.Dense(10, activation="sigmoid")
])

model.summary()

model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])
model.fit(train_ds, validation_data=val_ds,epochs=5)
```
--확률로 예측 해줌

학습시킨 모델을 저장하는법
저장되는 항목
- 레이어 설정
- loss 함수 종류
- optimizer 종류
- 훈련 후의 가중치들

1. 전체 모델 저장하기
model.save("경로+이름")

모델 불러오기
tf.keras.models.load_model(경로)



```python
model = tf.keras.models.load_model("/content/dogVScat.keras")
```


이미지 Augment(증강)
사진을 뒤틀거나 조작하여 다른(비슷한) 이미지를 만드는 것
1. 증강된 데이터 사본 생성
2. 모델에 넣기전에 데이터 증강(더 많이 씀)

```python
model = tf.keras.Sequential([
    # tf.keras.layers.Dense(128, input_shape=(28,28),activation="relu"),
    tf.keras.layers.experimental.preprocessing.RandomFlip("horizontal",input_shape=(64,64,3)),
    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),
    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),
    tf.keras.layers.Conv2D(32, (3,3), padding="same", activation="relu"),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Conv2D(32, (3,3), padding="same", activation="relu"),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(32, (3,3), padding="same", activation="relu"),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation="relu"),
    tf.keras.layers.Dense(1, activation="sigmoid")
])
```
이런 식으로 초기 사진에 변형을 주어서 새로운것처럼 보이게 할 수 있음. 매번 epochs마다 새로운 데이터처럼 보인다.

Tensorboard
loss, accuracy 등을 시각화 해줌

EarlyStopping